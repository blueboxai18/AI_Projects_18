{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"drd.ipynb","version":"0.3.2","provenance":[{"file_id":"1LS8wK0LeUQhGxorE9uFitOp5238zvDq3","timestamp":1550869618620}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"Q1qtaiZWOnZ8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"69fff19c-971b-44c1-a342-e447d2babd48","executionInfo":{"status":"ok","timestamp":1550872951642,"user_tz":300,"elapsed":39821,"user":{"displayName":"Murali K","photoUrl":"","userId":"09958326114285657721"}}},"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true,"id":"igONd2IaUFSl","colab_type":"code","outputId":"56bef07a-906f-43a4-d57b-fbd3a52f97b5","executionInfo":{"status":"ok","timestamp":1550873679164,"user_tz":300,"elapsed":751,"user":{"displayName":"Murali K","photoUrl":"","userId":"09958326114285657721"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["# https://www.pyimagesearch.com/2017/NUM_CLASSES/11/image-classification-with-keras-and-deep-learning/\n","# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n","# https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n","#https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import random\n","import sys\n","import cv2\n","import matplotlib\n","from subprocess import check_output\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","#list the files in the input directory\n","#print(os.listdir(\"../../../input\"))\n","print(os.listdir(\"/content/drive/My Drive/DRD/Input\"))\n","#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\")) #trainLabels.csv\n","print(check_output([\"ls\", \"/content/drive/My Drive/DRD/Input\"]).decode(\"utf8\")) #trainLabels.csv\n","#print(check_output([\"pwd\", \"\"]).decode(\"utf8\")) # /kaggle/working/\n","#classes : 0 - No DR, 1 - Mild, 2 - Moderate, 3 - Severe, 4 - Proliferative DR\n","def classes_to_int(label):\n","    # label = classes.index(dir)\n","    label = label.strip()\n","    if label == \"No DR\":  return 0\n","    if label == \"Mild\":  return 1\n","    if label == \"Moderate\":  return 2\n","    if label == \"Severe\":  return 3\n","    if label == \"Proliferative DR\":  return 4\n","    print(\"Invalid Label\", label)\n","    return 5\n","\n","def int_to_classes(i):\n","    if i == 0: return \"No DR\"\n","    elif i == 1: return \"Mild\"\n","    elif i == 2: return \"Moderate\"\n","    elif i == 3: return \"Severe\"\n","    elif i == 4: return \"Proliferative DR\"\n","    print(\"Invalid class \", i)\n","    return \"Invalid Class\""],"execution_count":13,"outputs":[{"output_type":"stream","text":["['A. Segmentation']\n","A. Segmentation\n","\n"],"name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"a8392f068f3887a4ef107e51530e2eb05fb3035a","id":"BwYB4nzdUFSq","colab_type":"code","colab":{}},"cell_type":"code","source":["NUM_CLASSES = 5\n","# we need images of same size so we convert them into the size\n","WIDTH = 128\n","HEIGHT = 128\n","DEPTH = 3\n","inputShape = (HEIGHT, WIDTH, DEPTH)\n","# initialize number of epochs to train for, initial learning rate and batch size\n","EPOCHS = 15\n","INIT_LR = 1e-3\n","BS = 32\n","#global variables\n","ImageNameDataHash = {}\n","uniquePatientIDList = []"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18c3c3a9599a32a49199918bef643166cde51928","id":"N0NeKVjjUFSu","colab_type":"code","colab":{}},"cell_type":"code","source":["def readTrainData(trainDir):\n","    global ImageNameDataHash\n","    # loop over the input images\n","    images = os.listdir(trainDir)\n","    print(\"Number of files in \" + trainDir + \" is \" + str(len(images)))\n","    for imageFileName in images:\n","        print(imageFileName)\n","        if (imageFileName == \"trainLabels.csv\"):\n","            continue\n","        # load the image, pre-process it, and store it in the data list\n","        imageFullPath = os.path.join(os.path.sep, trainDir, imageFileName)\n","        print(imageFullPath)\n","        img = load_img(imageFullPath)\n","        arr = img_to_array(img)  # Numpy array with shape (233,233,3)\n","        dim1 = arr.shape[0]\n","        dim2 = arr.shape[1]\n","        dim3 = arr.shape[2]\n","        if (dim1 < HEIGHT or dim2 < WIDTH or dim3 < DEPTH):\n","            print(\"Error image dimensions are less than expected \"+str(arr.shape))\n","        arr = cv2.resize(arr, (HEIGHT,WIDTH)) #Numpy array with shape (HEIGHT, WIDTH,3)\n","        #print(arr.shape) # 128,128,3\n","        dim1 = arr.shape[0]\n","        dim2 = arr.shape[1]\n","        dim3 = arr.shape[2]\n","        if (dim1 != HEIGHT or dim2 != WIDTH or dim3 != DEPTH):\n","            print(\"Error after resize, image dimensions are not equal to expected \"+str(arr.shape))\n","        #print(type(arr))\n","        # scale the raw pixel intensities to the range [0, 1] - TBD TEST\n","        arr = np.array(arr, dtype=\"float\") / 255.0\n","        imageFileName = imageFileName.replace('.jpeg','')\n","        print(imageFileName)\n","        ImageNameDataHash[str(imageFileName)] = np.array(arr) \n","    return"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a255507029c703ab70b7bd82e2dba11487abf73a","id":"9LNf-y3NUFSy","colab_type":"code","colab":{}},"cell_type":"code","source":["from datetime import datetime\n","print(\"Loading images at...\"+ str(datetime.now()))\n","sys.stdout.flush()\n","#readTrainData(\"/kaggle/working/../input/\")\n","readTrainData(\"/content/drive/My Drive/DRD/Input/A. Segmentation/1. Original Images/a. Training Set/\")\n","\n","\n","print(\"Loaded \" + str(len(ImageNameDataHash)) + \" images at...\"+ str(datetime.now())) # 1000"],"execution_count":0,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"id":"kzvVhngkUFS1","colab_type":"code","colab":{}},"cell_type":"code","source":["#csv contains image\tlevel\n","#10_left 0\n","#10_right 0\n","import csv\n","def readTrainCsv():\n","    raw_df = pd.read_csv('/kaggle/working/../input/trainLabels.csv', sep=',')\n","    print(type(raw_df)) #<class 'pandas.core.frame.DataFrame'>\n","    row_count=raw_df.shape[0] #gives number of row count row_count=35126 \n","    col_count=raw_df.shape[1] #gives number of col count col count=2\n","    print(\"row_count=\"+str(row_count)+\" col count=\"+str(col_count))\n","    raw_df[\"PatientID\"] = ''\n","    header_list = list(raw_df.columns)\n","    print(header_list) # ['image', 'level', 'PatientID']\n","    # double check if level of left and right are same or not\n","    ImageLevelHash = {}\n","    patientIDList = []\n","    for index, row in raw_df.iterrows():\n","        # 0 is image, 1 is level, 2 is PatientID, 3 is data\n","        key = row[0] + ''\n","        patientID = row[0] + ''\n","        patientID = patientID.replace('_right','')\n","        patientID = patientID.replace('_left','')\n","        #print(\"Adding patient ID\"+ patientID)\n","        raw_df.at[index, 'PatientID'] = patientID\n","        patientIDList.append(patientID)\n","        ImageLevelHash[key] = str(row[1]) # level\n","                \n","    global uniquePatientIDList\n","    uniquePatientIDList = sorted(set(patientIDList))\n","    count=0;\n","    for patientID in uniquePatientIDList:\n","        left_level = ImageLevelHash[str(patientID+'_left')]\n","        right_level = ImageLevelHash[str(patientID+'_right')]\n","        #right_exists = str(patientID+'_right') in raw_df.values\n","        if (left_level != right_level):\n","            count = count+1\n","            #print(\"Warning for patient=\"+ str(patientID) + \" left_level=\" + left_level+ \" right_level=\" +right_level)\n","    print(\"count of images with both left and right eye level not matching=\"+str(count)) # 2240\n","    print(\"number of unique patients=\"+str(len(uniquePatientIDList))) # 17563\n","    return raw_df"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da157990920eda7c89bd96f6457cf2696d45b01b","scrolled":true,"id":"E4614F6jUFS6","colab_type":"code","colab":{}},"cell_type":"code","source":["random.seed(10)\n","print(\"Reading trainLabels.csv...\")\n","df = readTrainCsv()"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbceaf7b7abd5a2c2f562b63f2ead55c00e451e2","id":"L6gXv9HjUFS-","colab_type":"code","colab":{}},"cell_type":"code","source":["for i in range(0,10):\n","    s = df.loc[df.index[i], 'PatientID'] # get patient id of patients\n","    print(str(i) + \" patient's patientID=\"+str(s))"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98a5849022c032a33b2d75f54ec2d05da2cd9245","id":"qNKtxwppUFTC","colab_type":"code","colab":{}},"cell_type":"code","source":["# df has 3 columns ['image', 'level', 'PatientID']\n","keepImages =  list(ImageNameDataHash.keys())\n","df = df[df['image'].isin(keepImages)]\n","print(len(df)) # 1000"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d8c229035728a04562a428aed1b685974e172e8","id":"W_heDbqVUFTG","colab_type":"code","colab":{}},"cell_type":"code","source":["#convert hash to dataframe\n","imageNameArr = []\n","dataArr = []\n","for index, row in df.iterrows():\n","    key = str(row[0])\n","    if key in ImageNameDataHash:\n","        imageNameArr.append(key)\n","        dataArr.append(np.array(ImageNameDataHash[key])) # np.array\n","\n","df2 = pd.DataFrame({'image': imageNameArr, 'data': dataArr})\n","df2_header_list = list(df2.columns) \n","print(df2_header_list) # ['image', 'data']\n","print(len(df2)) # 1000\n","#print(df2.describe(include='all'))\n","#print(df2.sample(3)) # 3 rows x 2 columns"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea37d7a5dffecdb0744c223090c98c91ee097ccf","id":"SNVWACchUFTL","colab_type":"code","colab":{}},"cell_type":"code","source":["if len(df) != len(df2):\n","    print(\"Error length of df != df2\")\n","    \n","for idx in range(0,len(df)):\n","    if (df.loc[df.index[idx], 'image'] != df2.loc[df2.index[idx], 'image']):\n","        print(\"Error \" + df.loc[df.index[idx], 'image'] +\"==\" + df2.loc[df2.index[idx], 'image'])\n","        \n","print(df2.dtypes)\n","print(df.dtypes)"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3fd926f29c25be1bd728da76c175e283b1fac83","id":"Ku5eO48yUFTQ","colab_type":"code","colab":{}},"cell_type":"code","source":["df = pd.merge(df2, df, left_on='image', right_on='image', how='outer')\n","df_header_list = list(df.columns) \n","print(df_header_list) # 'image', 'data', level', 'PatientID'\n","print(len(df)) # 1000\n","print(df.sample())"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25fd586d9cc4b7a1beeb2e8c7cdee896f068b8c6","id":"5ulkLmGcUFTV","colab_type":"code","colab":{}},"cell_type":"code","source":["sample0 = df.loc[df.index[0], 'data']\n","print(sample0)\n","print(type(sample0)) # <class 'numpy.ndarray'>\n","print(sample0.shape) # 128,128,3\n","from matplotlib import pyplot as plt\n","plt.imshow(sample0, interpolation='nearest')\n","plt.show()\n","print(\"Sample Image\")"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5de4e16737d21bd5c842e3b3fe7ca16b3177f76a","id":"9DSBxnuYUFTZ","colab_type":"code","colab":{}},"cell_type":"code","source":["X = df['data']\n","Y = df['level']\n","# scale the raw pixel intensities to the range [0, 1]\n","#print(type(X)) # 'pandas.core.series.Series'\n","#X = np.array(X, dtype=\"float\") / 255.0 -- TBD moved to top\n","Y = np.array(Y)\n","# convert the labels from integers to vectors\n","Y =  to_categorical(Y, num_classes=NUM_CLASSES)"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4550440da8759c52ed43bfe0737bfa2684e7583c","id":"CSXITAzcUFTc","colab_type":"code","colab":{}},"cell_type":"code","source":["# partition the data into training and testing splits using 75% training and 25% for validation\n","print(\"Parttition data into 75:25...\")\n","sys.stdout.flush()\n","print(\"Unique patients in dataframe df=\" + str(df.PatientID.nunique())) # 500\n","unique_ids = df.PatientID.unique()\n","print('unique_ids shape='+ str(len(unique_ids))) #500\n","\n","# Refer https://www.kaggle.com/kmader/tf-data-tutorial-with-retina-and-keras\n","train_ids, valid_ids = train_test_split(unique_ids, test_size = 0.25, random_state = 10) #stratify = rr_df['level'])\n","trainid_list = train_ids.tolist()\n","print('trainid_list shape=', str(len(trainid_list))) # 375\n","\n","traindf = df[df.PatientID.isin(trainid_list)]\n","valSet = df[~df.PatientID.isin(trainid_list)]"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07f4a9232379f1c7057f9921ad372266caadd887","id":"JHDneIMlUFTg","colab_type":"code","colab":{}},"cell_type":"code","source":["print(traindf.head())\n","print(valSet.head())\n","\n","traindf = traindf.reset_index(drop=True)\n","valSet = valSet.reset_index(drop=True)\n","\n","print(traindf.head())\n","print(valSet.head())"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19f9a8d5aba3229deecf254d2db0b7e5c5cbd81f","id":"ElQoyBh6UFTk","colab_type":"code","colab":{}},"cell_type":"code","source":["trainX = traindf['data']\n","trainY = traindf['level']\n","\n","valX = valSet['data']\n","valY = valSet['level']\n","\n","#(trainX, valX, trainY, valY) = train_test_split(X,Y,test_size=0.25, random_state=10)\n","print('trainX shape=', trainX.shape[0], 'valX shape=', valX.shape[0]) # 750, 250"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6673e914026947e96d26318834ed6ac914ab4e9d","id":"dYpSc08uUFTu","colab_type":"code","colab":{}},"cell_type":"code","source":["trainY =  to_categorical(trainY, num_classes=NUM_CLASSES)\n","valY =  to_categorical(valY, num_classes=NUM_CLASSES)"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8925ee30a9086c36f0e8f7cc88ff24e177870051","id":"ADZvV9n0UFT3","colab_type":"code","colab":{}},"cell_type":"code","source":["#construct the image generator for data augmentation\n","print(\"Generating images...\")\n","sys.stdout.flush()\n","aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \\\n","    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\\\n","    horizontal_flip=True, fill_mode=\"nearest\")"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff8002067d4fb19fd8ef9634f3bab2a8daa35b1a","id":"C2zu7qaaUFT9","colab_type":"code","colab":{}},"cell_type":"code","source":["def createModel():\n","    model = Sequential()\n","    # first set of CONV => RELU => MAX POOL layers\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=inputShape))\n","    model.add(Conv2D(32, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","    \n","    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","    \n","    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","    \n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(output_dim=NUM_CLASSES, activation='softmax'))\n","    # returns our fully constructed deep learning + Keras image classifier \n","    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","    # use binary_crossentropy if there are two classes\n","    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55ee93f18f850e1fb144e578778a3b5420637684","id":"S64-SIgBUFUA","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"Reshaping trainX at...\"+ str(datetime.now()))\n","#print(trainX.sample()) \n","print(type(trainX)) # <class 'pandas.core.series.Series'>\n","print(trainX.shape) # (750,)\n","from numpy import zeros\n","Xtrain = np.zeros([trainX.shape[0],HEIGHT, WIDTH, DEPTH])\n","for i in range(trainX.shape[0]): # 0 to traindf Size -1\n","    Xtrain[i] = trainX[i]\n","print(Xtrain.shape) # (750,128,128,3)\n","print(\"Reshaped trainX at...\"+ str(datetime.now()))"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f61c84f7f96522c7355bd126c8722676c8e3836","id":"2ubPaJ4vUFUD","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"Reshaping valX at...\"+ str(datetime.now()))\n","print(type(valX)) # <class 'pandas.core.series.Series'>\n","print(valX.shape) # (250,)\n","from numpy import zeros\n","Xval = np.zeros([valX.shape[0],HEIGHT, WIDTH, DEPTH])\n","for i in range(valX.shape[0]): # 0 to traindf Size -1\n","    Xval[i] = valX[i]\n","print(Xval.shape) # (250,128,128,3)\n","print(\"Reshaped valX at...\"+ str(datetime.now()))"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a66f5862854d1b03730a172f38ef25465fd2421","id":"CFeNfPNBUFUG","colab_type":"code","colab":{}},"cell_type":"code","source":["# initialize the model\n","print(\"compiling model...\")\n","sys.stdout.flush()\n","model = createModel()\n","\n","# print the summary of model\n","from keras.utils import print_summary\n","print_summary(model, line_length=None, positions=None, print_fn=None)\n","\n","# add some visualization\n","from IPython.display import SVG\n","from keras.utils.vis_utils import model_to_dot\n","SVG(model_to_dot(model).create(prog='dot', format='svg'))"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"701909840ec8ee1f5da90a8cac0902d880d4f79a","id":"oyQWJi2aUFUK","colab_type":"code","colab":{}},"cell_type":"code","source":["# train the network\n","print(\"training network...\")\n","sys.stdout.flush()\n","#class_mode ='categorical', # 2D one-hot encoded labels\n","H = model.fit_generator(aug.flow(Xtrain, trainY, batch_size=BS), \\\n","    validation_data=(Xval, valY), \\\n","    steps_per_epoch=len(trainX) // BS, \\\n","    epochs=EPOCHS, verbose=1)\n","\n","# save the model to disk\n","print(\"Saving model to disk\")\n","sys.stdout.flush()\n","model.save(\"/tmp/mymodel\")"],"execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebaac96c16fc39a6665ac3e8917ca856029f12dc","id":"G5qjvUCOUFUM","colab_type":"code","colab":{}},"cell_type":"code","source":["# set the matplotlib backend so figures can be saved in the background\n","# plot the training loss and accuracy\n","print(\"Generating plots...\")\n","sys.stdout.flush()\n","matplotlib.use(\"Agg\")\n","matplotlib.pyplot.style.use(\"ggplot\")\n","matplotlib.pyplot.figure()\n","N = EPOCHS\n","matplotlib.pyplot.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n","matplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n","matplotlib.pyplot.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n","matplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n","matplotlib.pyplot.title(\"Training Loss and Accuracy on diabetic retinopathy detection\")\n","matplotlib.pyplot.xlabel(\"Epoch #\")\n","matplotlib.pyplot.ylabel(\"Loss/Accuracy\")\n","matplotlib.pyplot.legend(loc=\"lower left\")\n","matplotlib.pyplot.savefig(\"plot.png\")"],"execution_count":0,"outputs":[]}]}